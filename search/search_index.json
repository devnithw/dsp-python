{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Digital Signal Processing Projects","text":"<p>This is a collection of notebooks including projects that I have completed on digital signal processing. Full github repository can be found out here</p>"},{"location":"#topics-discussed","title":"Topics discussed","text":""},{"location":"#denoising","title":"Denoising","text":"<ul> <li>Denoising with Fast Fourier Transform (link)</li> </ul>"},{"location":"#digital-filtering","title":"Digital filtering","text":""},{"location":"#feature-extraction","title":"Feature extraction","text":""},{"location":"#scientific-analysis","title":"Scientific Analysis","text":"<p>About Me</p> <p>I am Devnith Wijesinghe, a second year Biomedical Engineering undergraduate at University of Moratuwa. I am interested in learning about signal processing and deep learning. I write articles and tutorials about what I learn so I created this collection of mini-projects that I have done to share with the world. Feel free to reach me at wijesinghecd.21@uom.lk</p>"},{"location":"communications_channel/","title":"Modelling a communication channel using Python","text":"In\u00a0[1]: Copied! <pre># Import libraries\nimport numpy as np\nfrom scipy.io import wavfile\nimport IPython\n\n# Plotting\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n# Set figure size\nplt.rcParams[\"figure.figsize\"] = (14,4)\n</pre> # Import libraries import numpy as np from scipy.io import wavfile import IPython  # Plotting %matplotlib inline import matplotlib import matplotlib.pyplot as plt  # Set figure size plt.rcParams[\"figure.figsize\"] = (14,4) In\u00a0[2]: Copied! <pre># Read speech signal\nsampling_rate, speech = wavfile.read('assets/audio/speech.wav')\n\n# Visualize and play the audio\nplt.plot(speech);\nIPython.display.Audio(speech, rate=sampling_rate)\n</pre> # Read speech signal sampling_rate, speech = wavfile.read('assets/audio/speech.wav')  # Visualize and play the audio plt.plot(speech); IPython.display.Audio(speech, rate=sampling_rate) Out[2]:                      Your browser does not support the audio element.                  In\u00a0[3]: Copied! <pre># Normalize the raw audio\nnormalized = 1.0 / max(np.absolute([min(speech), max(speech)]))\nanalogSignal = 100.0 * speech * normalized\n</pre> # Normalize the raw audio normalized = 1.0 / max(np.absolute([min(speech), max(speech)])) analogSignal = 100.0 * speech * normalized <p>Now to model the digital version of this processed signal we will round off its amplitudes into nearest integers. We can change the step size (amplitude difference between two levels) and observe how it affects the signal. Clearly the quality of the audio drops when we increase the step size.</p> In\u00a0[70]: Copied! <pre>STEP_SIZE = 5\n\n# Round up the analog signal to the digitized levels\ndigitalSignal = np.round(analogSignal / STEP_SIZE ) * STEP_SIZE\n</pre> STEP_SIZE = 5  # Round up the analog signal to the digitized levels digitalSignal = np.round(analogSignal / STEP_SIZE ) * STEP_SIZE In\u00a0[5]: Copied! <pre>def SNR(noisy_signal, clean_signal):\n    # Noise power\n    noisePower = np.linalg.norm(noisy_signal-clean_signal)\n    \n    # Signal power\n    signalPower = np.linalg.norm(clean_signal)\n    \n    # SNR measured in dBs\n    return 10 * np.log10(signalPower/noisePower)\n</pre> def SNR(noisy_signal, clean_signal):     # Noise power     noisePower = np.linalg.norm(noisy_signal-clean_signal)          # Signal power     signalPower = np.linalg.norm(clean_signal)          # SNR measured in dBs     return 10 * np.log10(signalPower/noisePower) <p>Now we can use this to measure the drop of quality between the analog and the digital signals</p> In\u00a0[6]: Copied! <pre>print ('SNR = %f dB' % SNR(digitalSignal, analogSignal))\n</pre> print ('SNR = %f dB' % SNR(digitalSignal, analogSignal)) <pre>SNR = 14.150821 dB\n</pre> <p>Change the step size and observe the change in SNR. As the step size is increased this quality drop becomes more audible.</p> In\u00a0[7]: Copied! <pre>IPython.display.Audio(analogSignal, rate=sampling_rate)\n</pre> IPython.display.Audio(analogSignal, rate=sampling_rate) Out[7]:                      Your browser does not support the audio element.                  In\u00a0[71]: Copied! <pre>IPython.display.Audio(digitalSignal, rate=sampling_rate)\n</pre> IPython.display.Audio(digitalSignal, rate=sampling_rate) Out[71]:                      Your browser does not support the audio element.                  <p>The less amplitude levels (bins) we have (i.e. the larger the step size), the lower will be the quality of the audio</p> In\u00a0[9]: Copied! <pre># Use less number of bins\nlowQSignal = np.round(analogSignal / 50 ) * 50\nIPython.display.Audio(lowQSignal, rate=sampling_rate)\n</pre> # Use less number of bins lowQSignal = np.round(analogSignal / 50 ) * 50 IPython.display.Audio(lowQSignal, rate=sampling_rate) Out[9]:                      Your browser does not support the audio element.                  <p>Now we have our analog signal and the digital signal of the same waveform. Let us now model our communications channel as a function. We will define the as a Additive White Gaussian Noise channel. We will pass the signal through this function.</p> <p>Remember that the channel can be modelled using the following equation:</p> <p>$$ Y(t) = A\\cdot X(t) + N(t)$$</p> <p>where,</p> <ul> <li>$Y(t)$ is the received signal</li> <li>$X(t)$ is the transmitted signal</li> <li>$A$ is the attenuation</li> <li>$N(t)$ is the AWGN noise</li> </ul> In\u00a0[78]: Copied! <pre>def channel(signal, noise_amplitude, attenuation, channel_length):\n    '''\n    signal - transmitted signal\n    noise_amplitude - AWGN noise introduced per unit length of the channel\n    attenuation - signal attenuation per unit length of the channel\n    channel_length - total length of the channel\n    '''\n    \n    # Create AWGN noise using distribution\n    noise = np.random.uniform(-noise_amplitude, noise_amplitude, len(signal))\n    \n    # Keep adding noise and attenuating for the whole length\n    for i in range(channel_length):\n        signal = attenuation * signal + 0.1* noise\n    \n    # Return the received output signal\n    return signal\n</pre> def channel(signal, noise_amplitude, attenuation, channel_length):     '''     signal - transmitted signal     noise_amplitude - AWGN noise introduced per unit length of the channel     attenuation - signal attenuation per unit length of the channel     channel_length - total length of the channel     '''          # Create AWGN noise using distribution     noise = np.random.uniform(-noise_amplitude, noise_amplitude, len(signal))          # Keep adding noise and attenuating for the whole length     for i in range(channel_length):         signal = attenuation * signal + 0.1* noise          # Return the received output signal     return signal <p>We will now pass each signal through the channel and receive them. When receiving the digital signal however, we have to make sure it is quantized. (Can only take specific values)</p> In\u00a0[79]: Copied! <pre>LENGTH = 70\nNOISE_AMPLITUDE = 0.01\nATTENUATION = 0.99\n\nyAnalog = channel(analogSignal, NOISE_AMPLITUDE, ATTENUATION, LENGTH)\nprint ('Analog trasmission: SNR = %f dB' % SNR(yAnalog, analogSignal))    \n\nyDigital = np.round(channel(digitalSignal, NOISE_AMPLITUDE, ATTENUATION, LENGTH) / STEP_SIZE ) * STEP_SIZE\nprint ('Digital trasmission: SNR = %f dB' % SNR(yDigital, analogSignal))\n</pre> LENGTH = 70 NOISE_AMPLITUDE = 0.01 ATTENUATION = 0.99  yAnalog = channel(analogSignal, NOISE_AMPLITUDE, ATTENUATION, LENGTH) print ('Analog trasmission: SNR = %f dB' % SNR(yAnalog, analogSignal))      yDigital = np.round(channel(digitalSignal, NOISE_AMPLITUDE, ATTENUATION, LENGTH) / STEP_SIZE ) * STEP_SIZE print ('Digital trasmission: SNR = %f dB' % SNR(yDigital, analogSignal))     <pre>Analog trasmission: SNR = 2.965656 dB\nDigital trasmission: SNR = 2.520522 dB\n</pre> In\u00a0[76]: Copied! <pre>IPython.display.Audio(yAnalog, rate=sampling_rate)\n</pre> IPython.display.Audio(yAnalog, rate=sampling_rate) Out[76]:                      Your browser does not support the audio element.                  In\u00a0[77]: Copied! <pre>IPython.display.Audio(yDigital, rate=sampling_rate)\n</pre> IPython.display.Audio(yDigital, rate=sampling_rate) Out[77]:                      Your browser does not support the audio element.                  In\u00a0[55]: Copied! <pre>NOISE_AMPLITUDE = 0.3\n\nyA = analog_tx(sA, NUM_REPEATERS, NOISE_AMPLITUDE, ATTENUATION)\nprint ('Analog trasmission: SNR = %f dB' % SNR(yA, sA))   \n\nyD = digital_tx(sD, NUM_REPEATERS, NOISE_AMPLITUDE, ATTENUATION)\nprint ('Digital trasmission: SNR = %f dB' % SNR(yD, sA))\n</pre> NOISE_AMPLITUDE = 0.3  yA = analog_tx(sA, NUM_REPEATERS, NOISE_AMPLITUDE, ATTENUATION) print ('Analog trasmission: SNR = %f dB' % SNR(yA, sA))     yD = digital_tx(sD, NUM_REPEATERS, NOISE_AMPLITUDE, ATTENUATION) print ('Digital trasmission: SNR = %f dB' % SNR(yD, sA))    <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[55], line 3\n      1 NOISE_AMPLITUDE = 0.3\n----&gt; 3 yA = analog_tx(sA, NUM_REPEATERS, NOISE_AMPLITUDE, ATTENUATION)\n      4 print ('Analog trasmission: SNR = %f dB' % SNR(yA, sA))   \n      6 yD = digital_tx(sD, NUM_REPEATERS, NOISE_AMPLITUDE, ATTENUATION)\n\nNameError: name 'sA' is not defined</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"communications_channel/#modelling-a-communication-channel-using-python","title":"Modelling a communication channel using Python\u00b6","text":""},{"location":"communications_channel/#introduction","title":"Introduction\u00b6","text":"<p>In this tutorial, we will model a communication channel and send a audio signal through. We will do this transmission in two different ways - Analog transmission - Digital transmission We will observe from the received signal and its corresponding SNR values how digital transmission is much more advantageous and immune to noise compared analog.</p>"},{"location":"communications_channel/#importing-the-libraries","title":"Importing the libraries\u00b6","text":"<p>First let us import the relevant frameworks to process audio. Since this is a simple project we will only use numpy and scipy.</p>"},{"location":"communications_channel/#read-audio-file","title":"Read audio file\u00b6","text":"<p>We will now read a speech signal in the form of a .wav file.</p> <p>Keep in mind that, this audio file is already a digital since computers only deal in digital signals.But for the sake of this simulation we will assume it is analog in nature.</p> <p>To model the digital version of this analog signal we will constrain its amplitudes to integer values.</p> <p>With these information in mind, we will read the audio while also recording the sampling rate at which it is sampled.(We can assume that the sampling rate is sufficiently large to conside this raw signal as analog)</p>"},{"location":"communications_channel/#preprocessing-audio","title":"Preprocessing audio\u00b6","text":"<p>Now we will simply preprocess this raw audio signal for easier processing and visualization. To do that we it is amplitude normalized to fit into +100 and -100.</p>"},{"location":"communications_channel/#signal-to-noise-ration-snr","title":"Signal to Noise Ration (SNR)\u00b6","text":"<p>The following function calculates SNR which is a metric to measure or compare the noise level of a signal.</p>"},{"location":"denoise_signal/","title":"Denoising a signal using FFT","text":"<p>Created on 28th January 2024</p> <p>In this notebook we will look experiment with obtaining the DFT of a signal corrupted with noise and work in the spectral domain to remove the noise.</p> <p>Concepts discussed:</p> <ul> <li>Discrete Fourier Transform</li> <li>Random Noise</li> <li>Filtering</li> </ul> <p>First let us import the relevant modules.</p> In\u00a0[2]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport IPython\n\nplt.rcParams['figure.figsize'] = (12, 3)\nplt.rcParams['font.size'] = 8\n\n%matplotlib inline\n</pre> import numpy as np import matplotlib.pyplot as plt import IPython  plt.rcParams['figure.figsize'] = (12, 3) plt.rcParams['font.size'] = 8  %matplotlib inline <p>Now that all libraries are imported, we will create a clean signal with two pure tones.</p> <p>Tone:  In signal processing, a tone is simply a sinusoidal signal with one specific frequency. Eg: 256 Hz tone is middle C in the piano.</p> <p>Our signal however is a combination of two tones namely <code>TONE1</code> and <code>TONE2</code>. You may change these values as you like.</p> In\u00a0[3]: Copied! <pre># Set delta time\ndt = 0.001\n\n# Define tones\nTONE1 = 50\nTONE2 = 120\n\n# Create the combined signal\nt = np.arange(0, 1, dt)\nx = np.sin(2 * np.pi * TONE1 * t) + np.sin(2 * np.pi * TONE2 * t)\n</pre> # Set delta time dt = 0.001  # Define tones TONE1 = 50 TONE2 = 120  # Create the combined signal t = np.arange(0, 1, dt) x = np.sin(2 * np.pi * TONE1 * t) + np.sin(2 * np.pi * TONE2 * t) <p>The signal in time domain representation is as follows,</p> <p>$$x(t) = sin(2 \\pi \\cdot 50t) + sin(2 \\pi \\cdot 120t) $$</p> <p>Now let's plot this signal to see how it looks.</p> In\u00a0[37]: Copied! <pre># Plot\nplt.plot(t, x, linewidth=1.0, color='b')\nplt.title('Clean signal');\nplt.xlim(t[0], t[-1]);\nplt.xlabel('Time');\nplt.ylabel('Amplitude');\n</pre> # Plot plt.plot(t, x, linewidth=1.0, color='b') plt.title('Clean signal'); plt.xlim(t[0], t[-1]); plt.xlabel('Time'); plt.ylabel('Amplitude'); <p>Although it is not a sinusoid now, clearly it has preserved some of the sinusoidal qualities like periodicity. Let's take a closer look.</p> In\u00a0[32]: Copied! <pre>plt.plot(t, x, linewidth=1.0, color='b')\nplt.title('Clean signal zoomed');\n\n# Zoom into a smaller region\nplt.xlim(0, 0.2);\n\nplt.xlabel('Time');\nplt.ylabel('Amplitude');\n</pre> plt.plot(t, x, linewidth=1.0, color='b') plt.title('Clean signal zoomed');  # Zoom into a smaller region plt.xlim(0, 0.2);  plt.xlabel('Time'); plt.ylabel('Amplitude'); <p>Now let us corrupt the signal with artificially generated noise. This noise $N(t)$ will be randomly generated.</p> <p>$$\\hat{x}(t) = x(t) + N(t)$$</p> In\u00a0[15]: Copied! <pre># Introduce random noise\nx_hat = x + 2.5 * np.random.randn(len(t))\n</pre> # Introduce random noise x_hat = x + 2.5 * np.random.randn(len(t)) In\u00a0[33]: Copied! <pre>plt.plot(t, x_hat, linewidth=1.0, color='b')\nplt.title('Corrupted signal');\nplt.xlim(t[0], t[-1]);\n\nplt.xlabel('Time');\nplt.ylabel('Amplitude');\n</pre> plt.plot(t, x_hat, linewidth=1.0, color='b') plt.title('Corrupted signal'); plt.xlim(t[0], t[-1]);  plt.xlabel('Time'); plt.ylabel('Amplitude'); <p>It is clear that all original signal properties has been lost. We see no periodicity or sinuosoidal nature. The signal shape is noisy.</p> <p>Let us now observe this corrupted signal in the frequency domain. To do this, we will use the <code>Fast Fourier Transform (FFT)</code> algorithm.</p> <p>Note The FFT computes the Discrete Fourier Transform (DFT) of a digital signal not the Discrete Time Fourier Transform.</p> <p>Also, note that spectrum is calculated from the DFT by,</p> <p>$$|X[k]|^2 = X[k] \\cdot X^*[k]$$</p> <p>where $X^*[k]$ is the complex conjugate of $X[k]$.</p> In\u00a0[21]: Copied! <pre># Take the FFT and obtain the DFT\nN = len(t)\nX = np.fft.fft(x_hat, N)\n\n# Use DFT to calculate spectrum\nspectrum = X * np.conj(X) / N\n\n# Normalize(Map) the digital frequency and plot\nfreq = 1 / (dt * N) * np.arange(N)\nL = np.arange(1, np.floor(N/2), dtype='int')\n</pre> # Take the FFT and obtain the DFT N = len(t) X = np.fft.fft(x_hat, N)  # Use DFT to calculate spectrum spectrum = X * np.conj(X) / N  # Normalize(Map) the digital frequency and plot freq = 1 / (dt * N) * np.arange(N) L = np.arange(1, np.floor(N/2), dtype='int') In\u00a0[28]: Copied! <pre>plt.plot(freq[L], spectrum[L], linewidth=1.0, color='r');\nplt.xlim(freq[L[0]], freq[L[-1]])\nplt.title('Spectrum of $x(t)$')\nplt.xlabel('frequency (k)')\nplt.ylabel('Spectrum $|X[k]|^2$')\nplt.show()\n</pre> plt.plot(freq[L], spectrum[L], linewidth=1.0, color='r'); plt.xlim(freq[L[0]], freq[L[-1]]) plt.title('Spectrum of $x(t)$') plt.xlabel('frequency (k)') plt.ylabel('Spectrum $|X[k]|^2$') plt.show()  <p>In the spectrum, we can observe two spikes at the <code>TONE1</code> and <code>TONE2</code> frequencies. Rest of the spectrum has ripples of small amplitudes which comes from the random noise. This is called a sea of noise. We need to remove or reduce these ripples to remove the noise from the signal.</p> <p>We will implement a simple solution to remove the noise, by making zero all the frequency components below a certain threshold. Since both the pure tone frequencies are above 100, we can select the <code>threshold</code> to be 100.</p> In\u00a0[31]: Copied! <pre>THRESHOLD = 100\n\n# Get k values which are higher than THRESHOLD\nindices = spectrum &gt; THRESHOLD\n\n# Make the rest zero\nfiltered = spectrum * indices\n\n# Filter the DFT also\nX = X * indices\n\n# Take inverse FFT\nfiltered_signal = np.fft.ifft(X)\n</pre> THRESHOLD = 100  # Get k values which are higher than THRESHOLD indices = spectrum &gt; THRESHOLD  # Make the rest zero filtered = spectrum * indices  # Filter the DFT also X = X * indices  # Take inverse FFT filtered_signal = np.fft.ifft(X) <p>The <code>ifft()</code> function takes the Inverse DFT according to the FFT algorithm. It gives back the time domain signal after doing the filtering.</p> In\u00a0[38]: Copied! <pre>plt.plot(freq[L], filtered[L], linewidth=1.0, color='r');\nplt.xlim(freq[L[0]], freq[L[-1]])\nplt.xlabel('frequency (k)')\nplt.ylabel('Spectrum $|X[k]|^2$')\nplt.show()\n</pre> plt.plot(freq[L], filtered[L], linewidth=1.0, color='r'); plt.xlim(freq[L[0]], freq[L[-1]]) plt.xlabel('frequency (k)') plt.ylabel('Spectrum $|X[k]|^2$') plt.show() <p>Note:  This is not actually a conventional digital filter. We are simply setting a threshold and removing all frequencies which are under that threshold.</p> In\u00a0[39]: Copied! <pre>plt.plot(t, filtered_signal, linewidth=1.0, color='b');\nplt.xlim(t[0], t[-1])\nplt.xlabel('Time');\nplt.ylabel('Amplitude');\nplt.show()\n</pre> plt.plot(t, filtered_signal, linewidth=1.0, color='b'); plt.xlim(t[0], t[-1]) plt.xlabel('Time'); plt.ylabel('Amplitude'); plt.show() <p>As you can see, the noisy signal is reverted back to the originial clean signal.</p>"},{"location":"denoise_signal/#denoising-a-signal-using-fft","title":"Denoising a signal using FFT\u00b6","text":""},{"location":"denoise_signal/#import-modules","title":"Import modules\u00b6","text":""},{"location":"denoise_signal/#generate-a-signal-and-corrupt-it-with-noise","title":"Generate a signal and corrupt it with noise\u00b6","text":""},{"location":"denoise_signal/#taking-the-fft","title":"Taking the FFT\u00b6","text":""},{"location":"denoise_signal/#filtering-noise","title":"Filtering noise\u00b6","text":""},{"location":"denoise_signal/#frequency-plot-after-filtering","title":"Frequency plot after filtering\u00b6","text":""},{"location":"denoise_signal/#time-domain-plot-after-filtering","title":"Time domain plot after filtering\u00b6","text":""},{"location":"ecg_conditioning/","title":"ECG signal conditioning using SciPy","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport csv\nimport matplotlib.pyplot as plt\nfrom scipy import signal\nfrom scipy.fftpack import fft, fftshift, ifft\n\nplt.rcParams['figure.figsize'] = (12, 3)\nplt.rcParams['font.size'] = 8\n\n%matplotlib inline\n</pre> import numpy as np import csv import matplotlib.pyplot as plt from scipy import signal from scipy.fftpack import fft, fftshift, ifft  plt.rcParams['figure.figsize'] = (12, 3) plt.rcParams['font.size'] = 8  %matplotlib inline In\u00a0[2]: Copied! <pre>ecg_values = []\nfile = 'assets/ecg_signal.csv'\n\nwith open(file, 'r') as file:\n    csv_reader = csv.reader(file)\n    for row in csv_reader:\n        ecg_values.append(float(row[0]))\n</pre> ecg_values = [] file = 'assets/ecg_signal.csv'  with open(file, 'r') as file:     csv_reader = csv.reader(file)     for row in csv_reader:         ecg_values.append(float(row[0])) In\u00a0[3]: Copied! <pre># Convert the list to a NumPy array\necg = np.array(ecg_values)\n\nplt.plot(ecg, linewidth=1.0, color='b')\nplt.title('ECG Waveform with powerline noise')\nplt.xlabel('time')\nplt.ylabel('amplitude')\nplt.xlim(0, len(ecg) - 1)\nplt.show()\n</pre> # Convert the list to a NumPy array ecg = np.array(ecg_values)  plt.plot(ecg, linewidth=1.0, color='b') plt.title('ECG Waveform with powerline noise') plt.xlabel('time') plt.ylabel('amplitude') plt.xlim(0, len(ecg) - 1) plt.show() In\u00a0[4]: Copied! <pre>plt.plot(ecg, linewidth=1.0, color='b')\nplt.title('ECG Waveform with powerline noise')\nplt.xlabel('time')\nplt.ylabel('amplitude')\nplt.xlim(0, 500)\nplt.show()\n</pre> plt.plot(ecg, linewidth=1.0, color='b') plt.title('ECG Waveform with powerline noise') plt.xlabel('time') plt.ylabel('amplitude') plt.xlim(0, 500) plt.show() In\u00a0[5]: Copied! <pre>N = len(ecg)\nX = np.fft.fft(ecg , N)\nspectrum = X * np.conj(X) / N\n\nduration = 10\ndt = 10 / N\n\nfreq = 1 / (dt * N) * np.arange(N)\nL = np.arange(1, np.floor(N/2), dtype='int')\n\nplt.plot(freq[L], spectrum[L], linewidth=1.0, color='r');\nplt.xlim(freq[L[0]], freq[L[-1]])\nplt.show()\n</pre> N = len(ecg) X = np.fft.fft(ecg , N) spectrum = X * np.conj(X) / N  duration = 10 dt = 10 / N  freq = 1 / (dt * N) * np.arange(N) L = np.arange(1, np.floor(N/2), dtype='int')  plt.plot(freq[L], spectrum[L], linewidth=1.0, color='r'); plt.xlim(freq[L[0]], freq[L[-1]]) plt.show() <pre>/Users/devnith/miniforge3/envs/pytorch/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1369: ComplexWarning: Casting complex values to real discards the imaginary part\n  return np.asarray(x, float)\n</pre> In\u00a0[6]: Copied! <pre>plt.plot(freq[L], spectrum[L], linewidth=1.0, color='r');\nplt.xlim(freq[L[0]], 80)\nplt.show()\n</pre> plt.plot(freq[L], spectrum[L], linewidth=1.0, color='r'); plt.xlim(freq[L[0]], 80) plt.show() In\u00a0[8]: Copied! <pre>print(N)\n</pre> print(N) <pre>3600\n</pre> In\u00a0[19]: Copied! <pre>\n</pre> Out[19]: <pre>&lt;matplotlib.legend.Legend at 0x150bc2070&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"ecg_conditioning/#ecg-signal-conditioning-using-scipy","title":"ECG signal conditioning using SciPy\u00b6","text":""}]}